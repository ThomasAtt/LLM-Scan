# LLM-Scan
LLM-Scan是一款用于大模型攻击测试的工具，模拟提示词注入等场景用以测试大模型的安全性
